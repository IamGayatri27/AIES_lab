{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamGayatri27/AIES_lab/blob/main/ex2_aies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name : Gayatri Sagar Chougale\n",
        "PRN  :22SC114501085\n",
        "Class: B.tech 'B'\n",
        "Title: Detecting algorithmic bias in hiring dataset\n"
      ],
      "metadata": {
        "id": "MMq7Y54Ly5TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairlearn"
      ],
      "metadata": {
        "id": "_j9HUBF_xqlA",
        "outputId": "093c998b-2189-4649-ef1d-0628257de00e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.11/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fairlearn.metrics import (\n",
        "    MetricFrame,\n",
        "    true_positive_rate,\n",
        "    false_positive_rate,\n",
        "    false_negative_rate,\n",
        "    selection_rate,\n",
        "    demographic_parity_difference,\n",
        "    equalized_odds_difference\n",
        ")\n",
        "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n"
      ],
      "metadata": {
        "id": "3774KP3ZzKFy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/StudentsPerformance.csv')\n",
        "df['average_score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
        "df['pass_fail'] = (df['average_score'] >= 60).astype(int)\n",
        "categorical_cols = ['race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
        "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "features = [col for col in df.columns if col not in ['gender', 'average_score', 'pass_fail']]\n",
        "X = df[features]\n",
        "y = df['pass_fail']\n",
        "sensitive = df['gender']\n",
        "X_train, X_test, y_train, y_test, s_train, s_test = train_test_split(\n",
        "    X, y, sensitive, test_size=0.3, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "BxxLE9IbzJ9D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "rwzQW9mSzJ5i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_frame = MetricFrame(\n",
        "    metrics={\n",
        "        'Accuracy': accuracy_score,\n",
        "        'TPR': true_positive_rate,\n",
        "        'FPR': false_positive_rate,\n",
        "        'FNR': false_negative_rate,\n",
        "        'Selection Rate': selection_rate\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    sensitive_features=s_test\n",
        ")"
      ],
      "metadata": {
        "id": "ysM4AsnQzJ3H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Fairness Metrics by Gender ===\")\n",
        "print(metric_frame.by_group)\n",
        "print(\"\\nOverall Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Demographic Parity Difference:\", demographic_parity_difference(y_test, y_pred, sensitive_features=s_test))\n",
        "print(\"Equalized Odds Difference:\", equalized_odds_difference(y_test, y_pred, sensitive_features=s_test))\n"
      ],
      "metadata": {
        "id": "Fw1tndCtzJ0b",
        "outputId": "7f405986-6814-4034-f3fa-cacad7910356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Fairness Metrics by Gender ===\n",
            "        Accuracy  TPR  FPR  FNR  Selection Rate\n",
            "gender                                         \n",
            "female       1.0  1.0  0.0  0.0        0.790850\n",
            "male         1.0  1.0  0.0  0.0        0.632653\n",
            "\n",
            "Overall Accuracy: 1.0\n",
            "Demographic Parity Difference: 0.1581966119781245\n",
            "Equalized Odds Difference: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_estimator = LogisticRegression(max_iter=1000)\n",
        "constraint = DemographicParity()\n"
      ],
      "metadata": {
        "id": "IlsYffv2zJxy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mitigator = ExponentiatedGradient(base_estimator, constraints=constraint)\n",
        "mitigator.fit(X_train, y_train, sensitive_features=s_train)\n",
        "y_pred_mitigated = mitigator.predict(X_test)\n"
      ],
      "metadata": {
        "id": "VdUk1GF2zJuz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mitigated_frame = MetricFrame(\n",
        "    metrics={\n",
        "        'Accuracy': accuracy_score,\n",
        "        'TPR': true_positive_rate,\n",
        "        'FPR': false_positive_rate,\n",
        "        'FNR': false_negative_rate,\n",
        "        'Selection Rate': selection_rate\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred_mitigated,\n",
        "    sensitive_features=s_test\n",
        ")\n",
        "\n",
        "print(\"\\n=== After Mitigation ===\")\n",
        "print(mitigated_frame.by_group)\n",
        "print(\"\\nOverall Accuracy:\", accuracy_score(y_test, y_pred_mitigated))\n",
        "print(\"Demographic Parity Difference:\", demographic_parity_difference(y_test, y_pred_mitigated, sensitive_features=s_test))\n",
        "print(\"Equalized Odds Difference:\", equalized_odds_difference(y_test, y_pred_mitigated, sensitive_features=s_test))\n"
      ],
      "metadata": {
        "id": "m8CBVDe6zJem",
        "outputId": "837a90c1-571e-465f-84fc-fd7d1db282d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== After Mitigation ===\n",
            "        Accuracy       TPR       FPR       FNR  Selection Rate\n",
            "gender                                                        \n",
            "female  0.960784  0.958678  0.031250  0.041322        0.764706\n",
            "male    0.965986  1.000000  0.092593  0.000000        0.666667\n",
            "\n",
            "Overall Accuracy: 0.9633333333333334\n",
            "Demographic Parity Difference: 0.0980392156862745\n",
            "Equalized Odds Difference: 0.06134259259259259\n"
          ]
        }
      ]
    }
  ]
}